{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a010e5e-d572-4698-97c7-0c2dacb8bd86",
   "metadata": {},
   "source": [
    "# Scratch work and preliminary performance notes for `swe-python` with TT/QTT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17bfddaf-ad96-4965-8226-ff62c63c9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import argparse\n",
    "\n",
    "from stb import strtobool\n",
    "\n",
    "from msh import load_mesh, load_flow, \\\n",
    "                sort_mesh, sort_flow\n",
    "from ops import trsk_mats\n",
    "\n",
    "from _dx import HH_TINY, UU_TINY\n",
    "from _dx import invariant, diag_vars, tcpu\n",
    "from _dt import step_eqns\n",
    "\n",
    "import torch as tn\n",
    "import torchtt as tt\n",
    "\n",
    "from sympy.ntheory import factorint\n",
    "\n",
    "from temp_init import init_file\n",
    "from timer import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5fdab-b9ae-4d07-992e-d65935244f95",
   "metadata": {},
   "source": [
    "## Set up\n",
    "\n",
    "Here, we make a \"fake\" `cnfg` object with defaults since we don't have access to `argparse` from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e745169-12ea-4bad-8ac7-b8123f1ed6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class base: pass\n",
    "\n",
    "cnfg = base()\n",
    "\n",
    "cnfg.save_freq = 100\n",
    "cnfg.stat_freq = 100\n",
    "\n",
    "cnfg.integrate = 'RK44'\n",
    "cnfg.operators = 'TRSK-CV'\n",
    "cnfg.equations = 'SHALLOW-WATER'\n",
    "cnfg.ke_upwind = 'AUST-CONST'\n",
    "cnfg.ke_scheme = 'CENTRE'\n",
    "cnfg.pv_upwind = 'AUST-ADAPT'\n",
    "cnfg.pv_scheme = 'UPWIND'\n",
    "\n",
    "cnfg.du_damp_4 = 0.0\n",
    "cnfg.vu_damp_4 = 0.0\n",
    "\n",
    "cnfg.iteration = 0\n",
    "cnfg.no_rotate = False\n",
    "\n",
    "# testing with simple, quasi-linear\n",
    "# test case on low resolution mesh\n",
    "name = 'io/ltc1_cvt_5.nc'\n",
    "path, file = os.path.split(name)\n",
    "save = os.path.join(path, \"out_\" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db1c69-d688-4d4d-b8f4-dc4b0a5e50cc",
   "metadata": {},
   "source": [
    "Load configs, init file, and build the RHS TRiSK operators.\n",
    "\n",
    "The `flow` object stores the current model state, and the `mesh` object stores the mesh itself.\n",
    "\n",
    "The RHS operators are all stored in the `trsk` object -- these are built as `scipy.sparse.csr_matrix` objects (compressed sparse row matricies). Note that we often see lines of the form\n",
    "```\n",
    "trsk.<operator> * <state_vector>\n",
    "```\n",
    "This performs a matrix-vector multiply, using the soon-to-be-depreciated `*` symbol, overloaded with the proper sparse matrix multiplication routine.\n",
    "The modern standard is to use `@` as in `numpy` -- at present, both `*` and `@` do the same thing, with `@` to replace `*` in the next version of `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af83f10c-8c0f-4f3e-b853-68e905276c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading input assets...\n",
      "Creating output file...\n",
      "Reordering mesh data...\n",
      "Forming coefficients...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading input assets...\")\n",
    "\n",
    "# load mesh + init. conditions\n",
    "mesh = load_mesh(name)\n",
    "flow = load_flow(name, None, lean=True)\n",
    "\n",
    "\n",
    "print(\"Creating output file...\")\n",
    "\n",
    "init_file(name, cnfg, save, mesh, flow)\n",
    "\n",
    "\n",
    "print(\"Reordering mesh data...\")\n",
    "\n",
    "mesh = sort_mesh(mesh, True)\n",
    "flow = sort_flow(flow, mesh, lean=True)\n",
    "\n",
    "u0_edge = flow.uu_edge[-1, :, 0]\n",
    "uu_edge = u0_edge\n",
    "ut_edge = u0_edge * 0.0\n",
    "\n",
    "h0_cell = flow.hh_cell[-1, :, 0]\n",
    "hh_cell = h0_cell\n",
    "ht_cell = h0_cell * 0.0\n",
    "\n",
    "hh_cell = np.maximum(HH_TINY, hh_cell)\n",
    "\n",
    "\n",
    "print(\"Forming coefficients...\")\n",
    "\n",
    "# set sparse spatial operators\n",
    "trsk = trsk_mats(mesh)\n",
    "\n",
    "# remap fe,fc is more accurate?\n",
    "flow.ff_edge = trsk.edge_stub_sums * flow.ff_vert\n",
    "flow.ff_edge = \\\n",
    "    (flow.ff_edge / mesh.edge.area)\n",
    "\n",
    "flow.ff_cell = trsk.cell_kite_sums * flow.ff_vert\n",
    "flow.ff_cell = \\\n",
    "    (flow.ff_cell / mesh.cell.area)\n",
    "\n",
    "flow.ff_cell *= (not cnfg.no_rotate)\n",
    "flow.ff_edge *= (not cnfg.no_rotate)\n",
    "flow.ff_vert *= (not cnfg.no_rotate)\n",
    "\n",
    "kp_sums = np.zeros((\n",
    "    cnfg.iteration // cnfg.stat_freq + 1), dtype=float)\n",
    "en_sums = np.zeros((\n",
    "    cnfg.iteration // cnfg.stat_freq + 1), dtype=float)\n",
    "\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f2a7b-7de4-4ee2-a616-de323584e04c",
   "metadata": {},
   "source": [
    "# TT vs. CSR (defaults)\n",
    "\n",
    "Some preliminary performance tests.\n",
    "The CSRmatrix-vector multiply is very fast -- let's compare to TT multiply.\n",
    "\n",
    "Let's look at `trsk.edge_flux_perp`.\n",
    "This has shape `(nedges, nedges)` and multiplies `uu_edge` (normal velocity at cell edges) to get the tangential velocity at cell edges, e.g.\n",
    "```\n",
    "vv_edge = trsk.edge_flux_perp @ uu_edge\n",
    "```\n",
    "For our performance tests, we will work with a random `uu_edge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c91c2b-8cd0-4b6e-9ef1-0c181f565579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nedges = 30720\n"
     ]
    }
   ],
   "source": [
    "#uu_edge = np.random.rand(mesh.edge.size)\n",
    "uu_edge = np.ones(mesh.edge.size)\n",
    "print(f'nedges = {mesh.edge.size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f30c33e-8580-468b-91c3-d94371ebe950",
   "metadata": {},
   "source": [
    "Before getting to the performance tests, let's build the TT/QTT operator and tensors we need and look at how expensive this is.\n",
    "\n",
    "Since the number of edges here is not a multiple of 2, we can't trivially determine how to fold our tensors.\n",
    "For now, we will just use a prime factorization of the number of edges.\n",
    "\n",
    "For now, our operator matrix is square, so we will worry about how to fold a non-square matrix into a TT operator later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77885c1c-a26f-4e0d-abbb-ffc0aa4e945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prime_factors = [(2, 11), (3, 1), (5, 1)]\n",
      "tt_tens_shape = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "tt_op_shape = [(2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (3, 3), (5, 5)]\n"
     ]
    }
   ],
   "source": [
    "prime_factors = list( factorint(mesh.edge.size).items() )\n",
    "print(f'prime_factors = {prime_factors}')\n",
    "\n",
    "tt_tens_shape = []\n",
    "tt_op_shape = []\n",
    "for factor in prime_factors:\n",
    "    tt_tens_shape += [ factor[0] ] * factor[1]\n",
    "    tt_op_shape += [ (factor[0], factor[0]) ] * factor[1]\n",
    "# END for\n",
    "\n",
    "print(f'tt_tens_shape = {tt_tens_shape}')\n",
    "print(f'tt_op_shape = {tt_op_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81a4972-028f-4b7b-b043-1523d47fd651",
   "metadata": {},
   "source": [
    "Now, let's form the TT operator and corresponding TT tensor, which will have shapes `tt_op_shape` and `tt_tens_shape` respectivly.\n",
    "\n",
    "Notes:\n",
    "1) The compression on the random `tt_uu_edge` is *horrible* (more than 2x) when we use `uu_edge = np.random.rand(mesh.edge.size)`. If the flow was more realistic, maybe this wouldn't be so bad? Should look into this later. This also causes the python kernel to die on my LANL mac when we go to do the TT multiply later. For now, we will test with `uu_edge = np.ones(mesh.edge.size)`.\n",
    "3) It takes a long time to build `tt_edge_flux_perp`! With 30+ operators to build in this code, we could never do this at run time in practice. We would need to build/store once as associated with a given mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc0ecc13-13b5-435d-b394-3458e4d41cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt_uu_edge = TT with sizes and ranks:\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), 1]\n",
      "\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 30 compression 0.0009765625\n",
      "\n",
      "time to tt.TT(uu_edge) = 0.0016918182373046875\n",
      "\n",
      "tt_edge_flux_perp = TT-matrix with sizes and ranks:\n",
      "M = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 4, np.int64(10), np.int64(22), np.int64(46), np.int64(94), np.int64(212), np.int64(628), np.int64(1464), np.int64(2570), 900, 225, 25, 1]\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 29475394 compression 0.031233251359727647\n",
      "\n",
      "time to tt.TT(dense_edge_flux_perp) = 142.43342781066895\n"
     ]
    }
   ],
   "source": [
    "tt_op_timer = Timer()\n",
    "tt_round_op_timer = Timer()\n",
    "\n",
    "tt_tens_timer = Timer()\n",
    "\n",
    "# need to get dense version of the operator\n",
    "# to pass to tt.TT()\n",
    "dense_edge_flux_perp = trsk.edge_flux_perp.todense()\n",
    "\n",
    "\n",
    "# form the tt tensor\n",
    "tt_tens_timer.start()\n",
    "tt_uu_edge = tt.TT(uu_edge, tt_tens_shape)\n",
    "tt_tens_timer.stop()\n",
    "\n",
    "print(f'tt_uu_edge = {tt_uu_edge}')\n",
    "print(f'time to tt.TT(uu_edge) = {tt_tens_timer.get_time()}')\n",
    "\n",
    "\n",
    "# form the tt operator\n",
    "tt_op_timer.start()\n",
    "tt_edge_flux_perp = tt.TT(dense_edge_flux_perp, tt_op_shape)\n",
    "tt_op_timer.stop()\n",
    "\n",
    "print(f'\\ntt_edge_flux_perp = {tt_edge_flux_perp}')\n",
    "print(f'time to tt.TT(dense_edge_flux_perp) = {tt_op_timer.get_time()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3df153-7dd1-4571-88c3-0cef6fe2ff8c",
   "metadata": {},
   "source": [
    "The compression on the TT operator isnt bad, on the order of 1e-2.\n",
    "However, we also need to look at the compression obtained by the CSR representation of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01cb919a-05a6-4eaa-9f73-3a86d447de31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csr_nstored = 307140\n",
      "csr compression = 0.0003254572550455729\n"
     ]
    }
   ],
   "source": [
    "csr_nstored = trsk.edge_flux_perp.nnz\n",
    "print(f'csr_nstored = {csr_nstored}')\n",
    "print(f'csr compression = {csr_nstored / mesh.edge.size**2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac6c5a-5267-4bd3-b806-9ffa339d2531",
   "metadata": {},
   "source": [
    "CSR gives us a compression rate of 1e-4.\n",
    "Two orders of magnitude better than TT.\n",
    "\n",
    "Looking toward the possibility of representing the cores of `tt_edge_flux_perp` as sparse matrices, we should look the density of each core, i.e. the number of nonzero entries divided by the total number of entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90bfb92a-e8ba-4860-a1f7-a1a796d95a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density of core 0 = 0.375\n",
      "density of core 1 = 0.6000000238418579\n",
      "density of core 2 = 0.9670454263687134\n",
      "density of core 3 = 0.9903656244277954\n",
      "density of core 4 = 1.0\n",
      "density of core 5 = 1.0\n",
      "density of core 6 = 1.0\n",
      "density of core 7 = 1.0\n",
      "density of core 8 = 1.0\n",
      "density of core 9 = 1.0\n",
      "density of core 10 = 1.0\n",
      "density of core 11 = 1.0\n",
      "density of core 12 = 1.0\n"
     ]
    }
   ],
   "source": [
    "for i, core in enumerate(tt_edge_flux_perp.cores):\n",
    "    nnz = tn.count_nonzero(core)\n",
    "    tot = np.prod(core.shape)\n",
    "\n",
    "    print(f'density of core {i} = {nnz / tot}')\n",
    "# END for"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3782372a-a130-4616-8bd0-89aae2e997c1",
   "metadata": {},
   "source": [
    "These cores are **not** sparse.\n",
    "The original operator from which they arise is very sparse.\n",
    "So we can't represent the cores of a TT from a sparse matrix as sparse.\n",
    "This means that, at least sometimes (if not maybe most of the time), the TT of a sparse matrix requires more memory to store than an appropriately formatted sparse matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c0267-6970-40bc-b15f-e61e3a4dc73f",
   "metadata": {},
   "source": [
    "Let's look at multiplication speeds.\n",
    "First, at our TT multiply.\n",
    "Since linear algebra operations on TTs cause the rank of the result to increase, we generally round after each `@` (note the awful compression before rounding).\n",
    "We will time these two perations seperately, but understand that the total time is what is important.\n",
    "\n",
    "We also test two other methods of calculating (approximations to) this matvec product. \n",
    "`tt.TT.fast_matvec()` uses Density Matrix Renormalization Group (DMRG) iterations, and `tt._amen.amen_mv()` uses a Alternating Minimal Energy (AMEn) method.\n",
    "We could be using these wrong, but they are much slower than the default `__matmul__` which is invoked by `@` (which is a `torch.einsum()` underneath)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "350e25a4-28df-4a97-a601-f2b7ea23d8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt_mult_result (before round) = TT with sizes and ranks:\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 4, 10, 22, 46, 94, 212, 628, 1464, 2570, 900, 225, 25, 1]\n",
      "\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 14729072 compression 479.46197916666665\n",
      "\n",
      "time to @ = 0.016698837280273438\n",
      "\n",
      "tt_mult_result (after round) = TT with sizes and ranks:\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 2, 4, 8, 16, 32, 64, 128, 120, 60, 30, 15, 5, 1]\n",
      "\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 71714 compression 2.3344401041666667\n",
      "\n",
      "time to round = 0.12585902214050293\n",
      "\n",
      "total time = 0.28511571884155273\n"
     ]
    }
   ],
   "source": [
    "tt_mult_timer = Timer()\n",
    "tt_round_timer = Timer()\n",
    "\n",
    "tt_mult_timer.start()\n",
    "tt_mult_result = tt_edge_flux_perp @ tt_uu_edge\n",
    "tt_mult_timer.stop()\n",
    "\n",
    "print(f'tt_mult_result (before round) = {tt_mult_result}')\n",
    "print(f'time to @ = {tt_mult_timer.get_time()}')\n",
    "\n",
    "\n",
    "tt_round_timer.start()\n",
    "tt_mult_result = tt_mult_result.round()\n",
    "tt_round_timer.stop()\n",
    "\n",
    "print(f'\\ntt_mult_result (after round) = {tt_mult_result}')\n",
    "print(f'time to round = {tt_round_timer.get_time()}')\n",
    "\n",
    "print(f'\\ntotal time = {tt_mult_timer.get_time() + tt_round_timer.get_time()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f3dd4-89c2-4b95-8d54-95813ca4ce6b",
   "metadata": {},
   "source": [
    "This seems pretty slow, let's look at the CSR multiply and the ratio of the two times.\n",
    "Also, look at the compression for `tt_mult_result` -- extremely bad even after rounding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ebeaf77-069f-4bab-b8f0-e8d715f66195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt_mult_dmrg_result = TT with sizes and ranks:\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 2, 4, 8, 16, 32, 64, 128, 124, 64, 34, 19, 9, 1]\n",
      "\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 75662 compression 2.4629557291666666\n",
      "\n",
      "time to fast_matvec() = 0.7533509731292725\n"
     ]
    }
   ],
   "source": [
    "tt_mult_dmrg_timer = Timer()\n",
    "\n",
    "tt_mult_dmrg_timer.start()\n",
    "tt_mult_dmrg_result = tt.TT.fast_matvec(tt_edge_flux_perp, tt_uu_edge)\n",
    "tt_mult_dmrg_timer.stop()\n",
    "\n",
    "print(f'tt_mult_dmrg_result = {tt_mult_dmrg_result}')\n",
    "print(f'time to fast_matvec() = {tt_mult_dmrg_timer.get_time()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4dd97cea-95bf-4d24-96df-b30950708694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt_mult_amen_result = TT with sizes and ranks:\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 2, 4, 8, 16, 32, 64, 89, 89, 64, 34, 19, 9, 1]\n",
      "\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 50288 compression 1.6369791666666667\n",
      "\n",
      "time to amen_mv() = 6.566960096359253\n"
     ]
    }
   ],
   "source": [
    "tt_mult_amen_timer = Timer()\n",
    "\n",
    "tt_mult_amen_timer.start()\n",
    "tt_mult_amen_result = tt._amen.amen_mv(tt_edge_flux_perp, tt_uu_edge)\n",
    "tt_mult_amen_timer.stop()\n",
    "\n",
    "print(f'tt_mult_amen_result = {tt_mult_amen_result}')\n",
    "print(f'time to amen_mv() = {tt_mult_amen_timer.get_time()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d688eebf-bb57-4e5d-8db0-8e8c4293e6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csr mult time = 0.0007238388061523438\n",
      "tt mult time / csr mult time = 295.42045454545456\n"
     ]
    }
   ],
   "source": [
    "csr_mult_timer = Timer()\n",
    "\n",
    "csr_mult_timer.start()\n",
    "csr_mult_result = trsk.edge_flux_perp @ uu_edge\n",
    "csr_mult_timer.stop()\n",
    "\n",
    "print(f'csr mult time = {csr_mult_timer.get_time()}')\n",
    "\n",
    "\n",
    "print(f'tt mult time / csr mult time = {(tt_mult_timer.get_time() + tt_round_timer.get_time()) / csr_mult_timer.get_time()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb3e5c-9717-4328-8eab-367e678296a4",
   "metadata": {},
   "source": [
    "CSR multiply is over 200x faster than the TT multiply + rounding.\n",
    "\n",
    "The shape of the TT operator and the TT tensor could be important here, but it is hard to see how we are going to get 200x back. \n",
    "We could try padding the originall operator matrix and the state vector so that they have a size that is a multiple of 2 to get into true QTT format?\n",
    "\n",
    "For now, let's see how long it would take to do the full matrix-vector multiply. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01d82e9d-de95-4f86-8b6d-0d571de6af1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full mult time = 0.5088939666748047\n"
     ]
    }
   ],
   "source": [
    "full_mult_timer = Timer()\n",
    "\n",
    "full_mult_timer.start()\n",
    "full_mult_result = dense_edge_flux_perp @ uu_edge\n",
    "full_mult_timer.stop()\n",
    "\n",
    "print(f'full mult time = {full_mult_timer.get_time()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a1ed1-ca1e-4dc2-8fe0-9b8439d2e19e",
   "metadata": {},
   "source": [
    "This is sometimes faster than the TT multiply, sometimes slower.\n",
    "Taking all this together, I would not be surprised to learn that I am doing something wrong here.\n",
    "\n",
    "Finally, let's take a quick look at errors, taking `full_mult_result` as exact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf304c1f-639f-479d-855c-c1372521c088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csr_err = 1.1346079353288287e-28\n",
      "tt_err = 7.690421473359942e-23\n"
     ]
    }
   ],
   "source": [
    "csr_err = np.sum( np.square(full_mult_result - csr_mult_result) )\n",
    "print(f'csr_err = {csr_err}')\n",
    "\n",
    "tt_err = np.sum( np.square(full_mult_result - tt_mult_result.full().flatten().numpy()) )\n",
    "print(f'tt_err = {tt_err}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a2323f-6711-4984-8784-44d47a3d9051",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "With the above results, we need to do more if we expect to get good performance out of a potential TT method. Some thoughts:\n",
    "- Right now, the worst part seems to be the TT operator compression (and how long they take to calculate!). The CSR matrix form is both numerically exact and has a significantly smaller memory footprint.\n",
    "    - The default value of `eps` for `torchtt` is `eps=1e-10`. How much bigger does `eps` need to be in order to beat CSR on compression?\n",
    "    - Do we even want/need to represent the operators as TTs? Is it possible to do something like `CSR_tensor @ tt_vector`? This way, we would keep the great compression from CSR and still have an exact operator. Might want to look into `torch.sparse`. Is a sparse TT a thing? If not, why not?\n",
    "- We are not doing QTTs in all the above. A QTT has a shape of `[mode_size, mode_size, ..., mode_size]` and a total size of a power of `mode_size` (normally `mode_size = 2`).\n",
    "    - We can try padding both the operator and vectors with zeros so that their total size is a multiple of 2, then getting QTTs from there. I don't see this being 200x faster, but worth knowing for sure.\n",
    "    - This strategy would probably have dimishing returns as the mesh size(s) strays further from a power of 2.\n",
    "- We can also think about running these TT operations on a GPU -- something we can't do with CSR (at least right off the bat, there is probably a way with `torch`).\n",
    "    - Can/should we get some time on Darwin?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de890905-dc38-423c-96ac-836e2e98c48f",
   "metadata": {},
   "source": [
    "## TT compression and `eps`\n",
    "\n",
    "Lets see how time to compute and compression changes with `eps`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98b121ea-361e-47cd-8024-83cb69de64d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tt_edge_flux_perp_eps2 = TT-matrix with sizes and ranks:\n",
      "M = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 4, np.int64(10), np.int64(22), np.int64(46), np.int64(94), np.int64(207), np.int64(616), np.int64(1445), np.int64(2314), 900, 225, 25, 1]\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 26737330 compression 0.02833189434475369\n",
      "\n",
      "time to tt.TT(dense_edge_flux_perp_eps2) = 148.0722939968109\n"
     ]
    }
   ],
   "source": [
    "tt_op_timer_eps2 = Timer()\n",
    "\n",
    "# form the tt operator\n",
    "tt_op_timer_eps2.start()\n",
    "tt_edge_flux_perp_eps2 = tt.TT(dense_edge_flux_perp, tt_op_shape, eps=1e-2)\n",
    "tt_op_timer_eps2.stop()\n",
    "\n",
    "print(f'\\ntt_edge_flux_perp_eps2 = {tt_edge_flux_perp_eps2}')\n",
    "print(f'time to tt.TT(dense_edge_flux_perp_eps2) = {tt_op_timer_eps2.get_time()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97c985bf-94e0-4c62-aaa5-8b64612e79ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tt_edge_flux_perp_eps1 = TT-matrix with sizes and ranks:\n",
      "M = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 4, np.int64(10), np.int64(22), np.int64(46), np.int64(94), np.int64(190), np.int64(549), np.int64(1267), np.int64(1881), np.int64(880), np.int64(224), 25, 1]\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 20286945 compression 0.0214968204498291\n",
      "\n",
      "time to tt.TT(dense_edge_flux_perp_eps1 = 142.90259408950806\n"
     ]
    }
   ],
   "source": [
    "tt_op_timer_eps1 = Timer()\n",
    "\n",
    "# form the tt operator\n",
    "tt_op_timer_eps1.start()\n",
    "tt_edge_flux_perp_eps1 = tt.TT(dense_edge_flux_perp, tt_op_shape, eps=1e-1)\n",
    "tt_op_timer_eps1.stop()\n",
    "\n",
    "print(f'\\ntt_edge_flux_perp_eps1 = {tt_edge_flux_perp_eps1}')\n",
    "print(f'time to tt.TT(dense_edge_flux_perp_eps1 = {tt_op_timer_eps1.get_time()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbc1434b-67d5-4275-8dac-941b7b2d060a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tt_edge_flux_perp_eps0 = TT-matrix with sizes and ranks:\n",
      "M = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, np.int64(2), np.int64(4), np.int64(8), np.int64(15), np.int64(32), np.int64(87), np.int64(171), np.int64(271), np.int64(295), np.int64(175), np.int64(79), np.int64(17), 1]\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 852668 compression 0.000903519524468316\n",
      "\n",
      "time to tt.TT(dense_edge_flux_perp_eps0) = 40.85001492500305\n"
     ]
    }
   ],
   "source": [
    "tt_op_timer_eps0 = Timer()\n",
    "\n",
    "# form the tt operator\n",
    "tt_op_timer_eps0.start()\n",
    "tt_edge_flux_perp_eps0 = tt.TT(dense_edge_flux_perp, tt_op_shape, eps=1e-0)\n",
    "tt_op_timer_eps0.stop()\n",
    "\n",
    "print(f'\\ntt_edge_flux_perp_eps0 = {tt_edge_flux_perp_eps0}')\n",
    "print(f'time to tt.TT(dense_edge_flux_perp_eps0) = {tt_op_timer_eps0.get_time()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9479c171-a34c-43d1-be5f-608951e1d4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tt_edge_flux_perp_1eps = TT-matrix with sizes and ranks:\n",
      "M = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 78 compression 8.265177408854167e-08\n",
      "\n",
      "time to tt.TT(dense_edge_flux_perp_1eps) = 16.25500988960266\n"
     ]
    }
   ],
   "source": [
    "tt_op_timer_1eps = Timer()\n",
    "\n",
    "# form the tt operator\n",
    "tt_op_timer_1eps.start()\n",
    "tt_edge_flux_perp_1eps = tt.TT(dense_edge_flux_perp, tt_op_shape, eps=1e1)\n",
    "tt_op_timer_1eps.stop()\n",
    "\n",
    "print(f'\\ntt_edge_flux_perp_1eps = {tt_edge_flux_perp_1eps}')\n",
    "print(f'time to tt.TT(dense_edge_flux_perp_1eps) = {tt_op_timer_1eps.get_time()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "54bd9a6d-abb1-41ae-b1d7-b166da56f360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt_mult_result_eps (before round) = TT with sizes and ranks:\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 2, 4, 8, 16, 32, 64, 128, 120, 60, 30, 15, 5, 1]\n",
      "\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 71714 compression 2.3344401041666667\n",
      "\n",
      "time to @ = 0.06679534912109375\n",
      "\n",
      "tt_mult_result_eps (after round) = TT with sizes and ranks:\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 2, 4, 8, 15, 30, 60, 120, 120, 60, 30, 15, 5, 1]\n",
      "\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 67174 compression 2.186653645833333\n",
      "\n",
      "time to round = 0.015058040618896484\n",
      "\n",
      "total time = 0.03361988067626953\n",
      "tt_err = 2772.7722959686057\n"
     ]
    }
   ],
   "source": [
    "tt_mult_timer_eps = Timer()\n",
    "tt_round_timer_eps = Timer()\n",
    "\n",
    "tt_mult_timer_eps.start()\n",
    "tt_mult_result_eps = tt_edge_flux_perp_eps0 @ tt_uu_edge\n",
    "tt_mult_timer_eps.stop()\n",
    "\n",
    "print(f'tt_mult_result_eps (before round) = {tt_mult_result}')\n",
    "print(f'time to @ = {tt_mult_timer.get_time()}')\n",
    "\n",
    "\n",
    "tt_round_timer_eps.start()\n",
    "tt_mult_result_eps = tt_mult_result_eps.round()\n",
    "tt_round_timer_eps.stop()\n",
    "\n",
    "print(f'\\ntt_mult_result_eps (after round) = {tt_mult_result_eps}')\n",
    "print(f'time to round = {tt_round_timer_eps.get_time()}')\n",
    "\n",
    "print(f'\\ntotal time = {tt_mult_timer_eps.get_time() + tt_round_timer_eps.get_time()}')\n",
    "\n",
    "tt_err_eps = np.sum( np.square(full_mult_result - tt_mult_result_eps.full().flatten().numpy()) )\n",
    "print(f'tt_err = {tt_err_eps}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b480a43d-930e-463f-8ecf-ad78923c7d79",
   "metadata": {},
   "source": [
    "### Notes\n",
    "\n",
    "Summarizing the results from above.\n",
    "- As `eps` increases toward 1, the compression and compute time is mostly stagnate until around `1e-2` at which point it starts rapidly improving, but the error and time to multiply is unacceptable.\n",
    "- At `eps=10`, we reach the best case on compression, getting that the rank is `R = [1, 1, ..., 1]`. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
