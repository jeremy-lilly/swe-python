{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a010e5e-d572-4698-97c7-0c2dacb8bd86",
   "metadata": {},
   "source": [
    "Scratch work and preliminary performance notes for `swe-python` with TT/QTT."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17bfddaf-ad96-4965-8226-ff62c63c9fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import argparse\n",
    "\n",
    "from stb import strtobool\n",
    "\n",
    "from msh import load_mesh, load_flow, \\\n",
    "                sort_mesh, sort_flow\n",
    "from ops import trsk_mats\n",
    "\n",
    "from _dx import HH_TINY, UU_TINY\n",
    "from _dx import invariant, diag_vars, tcpu\n",
    "from _dt import step_eqns\n",
    "\n",
    "import torch as tn\n",
    "import torchtt as tt\n",
    "\n",
    "from sympy.ntheory import factorint\n",
    "\n",
    "from temp_init import init_file\n",
    "from timer import Timer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a5fdab-b9ae-4d07-992e-d65935244f95",
   "metadata": {},
   "source": [
    "Here, we make a \"fake\" `cnfg` object with defaults since we don't have access to `argparse` from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e745169-12ea-4bad-8ac7-b8123f1ed6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class base: pass\n",
    "\n",
    "cnfg = base()\n",
    "\n",
    "cnfg.save_freq = 100\n",
    "cnfg.stat_freq = 100\n",
    "\n",
    "cnfg.integrate = 'RK44'\n",
    "cnfg.operators = 'TRSK-CV'\n",
    "cnfg.equations = 'SHALLOW-WATER'\n",
    "cnfg.ke_upwind = 'AUST-CONST'\n",
    "cnfg.ke_scheme = 'CENTRE'\n",
    "cnfg.pv_upwind = 'AUST-ADAPT'\n",
    "cnfg.pv_scheme = 'UPWIND'\n",
    "\n",
    "cnfg.du_damp_4 = 0.0\n",
    "cnfg.vu_damp_4 = 0.0\n",
    "\n",
    "cnfg.iteration = 0\n",
    "cnfg.no_rotate = False\n",
    "\n",
    "# testing with simple, quasi-linear\n",
    "# test case on low resolution mesh\n",
    "name = 'io/ltc1_cvt_5.nc'\n",
    "path, file = os.path.split(name)\n",
    "save = os.path.join(path, \"out_\" + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5db1c69-d688-4d4d-b8f4-dc4b0a5e50cc",
   "metadata": {},
   "source": [
    "Load configs, init file, and build the RHS TRiSK operators.\n",
    "\n",
    "The `flow` object stores the current model state, and the `mesh` object stores the mesh itself.\n",
    "\n",
    "The RHS operators are all stored in the `trsk` object -- these are built as `scipy.sparse.csr_matrix` objects (compressed sparse row matricies). Note that we often see lines of the form\n",
    "```\n",
    "trsk.<operator> * <state_vector>\n",
    "```\n",
    "This performs a matrix-vector multiply, using the soon-to-be-depreciated `*` symbol, overloaded with the proper sparse matrix multiplication routine.\n",
    "The modern standard is to use `@` as in `numpy` -- at present, both `*` and `@` do the same thing, with `@` to replace `*` in the next version of `scipy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af83f10c-8c0f-4f3e-b853-68e905276c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading input assets...\n",
      "Creating output file...\n",
      "Reordering mesh data...\n",
      "Forming coefficients...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading input assets...\")\n",
    "\n",
    "# load mesh + init. conditions\n",
    "mesh = load_mesh(name)\n",
    "flow = load_flow(name, None, lean=True)\n",
    "\n",
    "\n",
    "print(\"Creating output file...\")\n",
    "\n",
    "init_file(name, cnfg, save, mesh, flow)\n",
    "\n",
    "\n",
    "print(\"Reordering mesh data...\")\n",
    "\n",
    "mesh = sort_mesh(mesh, True)\n",
    "flow = sort_flow(flow, mesh, lean=True)\n",
    "\n",
    "u0_edge = flow.uu_edge[-1, :, 0]\n",
    "uu_edge = u0_edge\n",
    "ut_edge = u0_edge * 0.0\n",
    "\n",
    "h0_cell = flow.hh_cell[-1, :, 0]\n",
    "hh_cell = h0_cell\n",
    "ht_cell = h0_cell * 0.0\n",
    "\n",
    "hh_cell = np.maximum(HH_TINY, hh_cell)\n",
    "\n",
    "\n",
    "print(\"Forming coefficients...\")\n",
    "\n",
    "# set sparse spatial operators\n",
    "trsk = trsk_mats(mesh)\n",
    "\n",
    "# remap fe,fc is more accurate?\n",
    "flow.ff_edge = trsk.edge_stub_sums * flow.ff_vert\n",
    "flow.ff_edge = \\\n",
    "    (flow.ff_edge / mesh.edge.area)\n",
    "\n",
    "flow.ff_cell = trsk.cell_kite_sums * flow.ff_vert\n",
    "flow.ff_cell = \\\n",
    "    (flow.ff_cell / mesh.cell.area)\n",
    "\n",
    "flow.ff_cell *= (not cnfg.no_rotate)\n",
    "flow.ff_edge *= (not cnfg.no_rotate)\n",
    "flow.ff_vert *= (not cnfg.no_rotate)\n",
    "\n",
    "kp_sums = np.zeros((\n",
    "    cnfg.iteration // cnfg.stat_freq + 1), dtype=float)\n",
    "en_sums = np.zeros((\n",
    "    cnfg.iteration // cnfg.stat_freq + 1), dtype=float)\n",
    "\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6f2a7b-7de4-4ee2-a616-de323584e04c",
   "metadata": {},
   "source": [
    "Some preliminary performance tests.\n",
    "The CSRmatrix-vector multiply is very fast -- let's compare to TT multiply.\n",
    "\n",
    "Let's look at `trsk.edge_flux_perp`.\n",
    "This has shape `(nedges, nedges)` and multiplies `uu_edge` (normal velocity at cell edges) to get the tangential velocity at cell edges, e.g.\n",
    "```\n",
    "vv_edge = trsk.edge_flux_perp @ uu_edge\n",
    "```\n",
    "For our performance tests, we will work with a random `uu_edge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32c91c2b-8cd0-4b6e-9ef1-0c181f565579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nedges = 30720\n"
     ]
    }
   ],
   "source": [
    "#uu_edge = np.random.rand(mesh.edge.size)\n",
    "uu_edge = np.ones(mesh.edge.size)\n",
    "print(f'nedges = {mesh.edge.size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f30c33e-8580-468b-91c3-d94371ebe950",
   "metadata": {},
   "source": [
    "Before getting to the performance tests, let's build the TT/QTT operator and tensors we need and look at how expensive this is.\n",
    "\n",
    "Since the number of edges here is not a multiple of 2, we can't trivially determine how to fold our tensors.\n",
    "For now, we will just use a prime factorization of the number of edges.\n",
    "\n",
    "For now, our operator matrix is square, so we will worry about how to fold a non-square matrix into a TT operator later..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77885c1c-a26f-4e0d-abbb-ffc0aa4e945c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prime_factors = [(2, 11), (3, 1), (5, 1)]\n",
      "tt_tens_shape = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "tt_op_shape = [(2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (3, 3), (5, 5)]\n"
     ]
    }
   ],
   "source": [
    "prime_factors = list( factorint(mesh.edge.size).items() )\n",
    "print(f'prime_factors = {prime_factors}')\n",
    "\n",
    "tt_tens_shape = []\n",
    "tt_op_shape = []\n",
    "for factor in prime_factors:\n",
    "    tt_tens_shape += [ factor[0] ] * factor[1]\n",
    "    tt_op_shape += [ (factor[0], factor[0]) ] * factor[1]\n",
    "# END for\n",
    "\n",
    "print(f'tt_tens_shape = {tt_tens_shape}')\n",
    "print(f'tt_op_shape = {tt_op_shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81a4972-028f-4b7b-b043-1523d47fd651",
   "metadata": {},
   "source": [
    "Now, let's form the TT operator and corresponding TT tensor, which will have shapes `tt_op_shape` and `tt_tens_shape` respectivly.\n",
    "\n",
    "Notes:\n",
    "1) The compression on the random `tt_uu_edge` is *horrible* (more than 2x) when we use `uu_edge = np.random.rand(mesh.edge.size)`. If the flow was more realistic, maybe this wouldn't be so bad? Should look into this later. This also causes the python kernel to die on my LANL mac when we go to do the TT multiply later. For now, we will test with `uu_edge = np.ones(mesh.edge.size)`.\n",
    "3) It takes a long time to build `tt_edge_flux_perp`! With 30+ operators to build in this code, we could never do this at run time in practice. We would need to build/store once as associated with a given mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc0ecc13-13b5-435d-b394-3458e4d41cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt_uu_edge = TT with sizes and ranks:\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), np.int64(1), 1]\n",
      "\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 30 compression 0.0009765625\n",
      "\n",
      "time to tt.TT(uu_edge) = 0.0015568733215332031\n",
      "\n",
      "tt_edge_flux_perp = TT-matrix with sizes and ranks:\n",
      "M = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 4, np.int64(10), np.int64(22), np.int64(46), np.int64(94), np.int64(212), np.int64(628), np.int64(1464), np.int64(2570), 900, 225, 25, 1]\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 29475394 compression 0.031233251359727647\n",
      "\n",
      "time to tt.TT(dense_edge_flux_perp) = 137.49320816993713\n"
     ]
    }
   ],
   "source": [
    "tt_op_timer = Timer()\n",
    "tt_round_op_timer = Timer()\n",
    "\n",
    "tt_tens_timer = Timer()\n",
    "\n",
    "# need to get dense version of the operator\n",
    "# to pass to tt.TT()\n",
    "dense_edge_flux_perp = trsk.edge_flux_perp.todense()\n",
    "\n",
    "\n",
    "# form the tt tensor\n",
    "tt_tens_timer.start()\n",
    "tt_uu_edge = tt.TT(uu_edge, tt_tens_shape)\n",
    "tt_tens_timer.stop()\n",
    "\n",
    "print(f'tt_uu_edge = {tt_uu_edge}')\n",
    "print(f'time to tt.TT(uu_edge) = {tt_tens_timer.get_time()}')\n",
    "\n",
    "\n",
    "# form the tt operator\n",
    "tt_op_timer.start()\n",
    "tt_edge_flux_perp = tt.TT(dense_edge_flux_perp, tt_op_shape)\n",
    "tt_op_timer.stop()\n",
    "\n",
    "print(f'\\ntt_edge_flux_perp = {tt_edge_flux_perp}')\n",
    "print(f'time to tt.TT(dense_edge_flux_perp) = {tt_op_timer.get_time()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3df153-7dd1-4571-88c3-0cef6fe2ff8c",
   "metadata": {},
   "source": [
    "The compression on the TT operator isnt bad, on the order of 1e-2.\n",
    "However, we also need to look at the compression obtained by the CSR representation of the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01cb919a-05a6-4eaa-9f73-3a86d447de31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csr_nstored = 307140\n",
      "csr compression = 0.0003254572550455729\n"
     ]
    }
   ],
   "source": [
    "csr_nstored = trsk.edge_flux_perp.nnz\n",
    "print(f'csr_nstored = {csr_nstored}')\n",
    "print(f'csr compression = {csr_nstored / mesh.edge.size**2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c0267-6970-40bc-b15f-e61e3a4dc73f",
   "metadata": {},
   "source": [
    "CSR gives us a compression rate of 1e-4.\n",
    "Two orders of magnitude better than TT.\n",
    "\n",
    "Let's look at multiplication speeds.\n",
    "First, at our TT multiply.\n",
    "Since linear algebra operations on TTs cause the rank of the result to increase, we generally round after each `@` (note the awful compression before rounding).\n",
    "We will time these two perations seperately, but understand that the total time is what is important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "350e25a4-28df-4a97-a601-f2b7ea23d8d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tt_mult_result (before round) = TT with sizes and ranks:\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 4, 10, 22, 46, 94, 212, 628, 1464, 2570, 900, 225, 25, 1]\n",
      "\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 14729072 compression 479.46197916666665\n",
      "\n",
      "time to @ = 0.017527103424072266\n",
      "\n",
      "tt_mult_result (after round) = TT with sizes and ranks:\n",
      "N = [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5]\n",
      "R = [1, 2, 4, 8, 16, 32, 64, 128, 120, 60, 30, 15, 5, 1]\n",
      "\n",
      "Device: cpu, dtype: torch.float64\n",
      "#entries 71714 compression 2.3344401041666667\n",
      "\n",
      "time to round = 0.12090015411376953\n",
      "\n",
      "total time = 0.2768545150756836\n"
     ]
    }
   ],
   "source": [
    "tt_mult_timer = Timer()\n",
    "tt_round_timer = Timer()\n",
    "\n",
    "tt_mult_timer.start()\n",
    "tt_mult_result = tt_edge_flux_perp @ tt_uu_edge\n",
    "tt_mult_timer.stop()\n",
    "\n",
    "print(f'tt_mult_result (before round) = {tt_mult_result}')\n",
    "print(f'time to @ = {tt_mult_timer.get_time()}')\n",
    "\n",
    "\n",
    "tt_round_timer.start()\n",
    "tt_mult_result = tt_mult_result.round()\n",
    "tt_round_timer.stop()\n",
    "\n",
    "print(f'\\ntt_mult_result (after round) = {tt_mult_result}')\n",
    "print(f'time to round = {tt_round_timer.get_time()}')\n",
    "\n",
    "print(f'\\ntotal time = {tt_mult_timer.get_time() + tt_round_timer.get_time()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5f3dd4-89c2-4b95-8d54-95813ca4ce6b",
   "metadata": {},
   "source": [
    "This seems pretty slow, let's look at the CSR multiply and the ratio of the two times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d688eebf-bb57-4e5d-8db0-8e8c4293e6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csr mult time = 0.0005898475646972656\n",
      "tt mult time / csr mult time = 352.0246564268391\n"
     ]
    }
   ],
   "source": [
    "csr_mult_timer = Timer()\n",
    "\n",
    "csr_mult_timer.start()\n",
    "csr_mult_result = trsk.edge_flux_perp @ uu_edge\n",
    "csr_mult_timer.stop()\n",
    "\n",
    "print(f'csr mult time = {csr_mult_timer.get_time()}')\n",
    "\n",
    "\n",
    "print(f'tt mult time / csr mult time = {(tt_mult_timer.get_time() + tt_round_timer.get_time()) / csr_mult_timer.get_time()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcb3e5c-9717-4328-8eab-367e678296a4",
   "metadata": {},
   "source": [
    "CSR multiply is over 200x faster than the TT multiply + rounding.\n",
    "\n",
    "The shape of the TT operator and the TT tensor could be important here, but it is hard to see how we are going to get 200x back. \n",
    "We could try padding the originall operator matrix and the state vector so that they have a size that is a multiple of 2 to get into true QTT format?\n",
    "\n",
    "For now, let's see how long it would take to do the full matrix-vector multiply. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01d82e9d-de95-4f86-8b6d-0d571de6af1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full mult time = 0.4231600761413574\n"
     ]
    }
   ],
   "source": [
    "full_mult_timer = Timer()\n",
    "\n",
    "full_mult_timer.start()\n",
    "full_mult_result = dense_edge_flux_perp @ uu_edge\n",
    "full_mult_timer.stop()\n",
    "\n",
    "print(f'full mult time = {full_mult_timer.get_time()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a1ed1-ca1e-4dc2-8fe0-9b8439d2e19e",
   "metadata": {},
   "source": [
    "This is sometimes faster than the TT multiply, sometimes slower.\n",
    "Taking all this together, I would not be surprised to learn that I am doing something wrong here.\n",
    "\n",
    "Finally, let's take a quick look at errors, taking `full_mult_result` as exact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf304c1f-639f-479d-855c-c1372521c088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csr_err = 1.1346079353288287e-28\n",
      "tt_err = 7.690421473359942e-23\n"
     ]
    }
   ],
   "source": [
    "csr_err = np.sum( np.square(full_mult_result - csr_mult_result) )\n",
    "print(f'csr_err = {csr_err}')\n",
    "\n",
    "tt_err = np.sum( np.square(full_mult_result - tt_mult_result.full().flatten().numpy()) )\n",
    "print(f'tt_err = {tt_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56775e32-0d5c-4e0a-8397-3497d133d944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
